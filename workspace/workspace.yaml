# k8s yaml to create a workspace: persistent volume, persistent volume claim, development pod, there are two pods:
# 1. ubuntu pod with a persistent volume mounted at /mnt/data, as command line editor and server runner e.g. next
# 2. kasm pod with a persistent volume mounted at /mnt/data, to offer desktop

---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "This priority class is for important pods."

---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: highest-priority
value: 1000001
globalDefault: false
description: "This priority class is for most important pods."


---
# nfs server
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: nfs-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfs-server
  template:
    metadata:
      labels:
        app: nfs-server
    spec:
      priorityClassName: highest-priority
      nodeSelector:
        mylabel: core
      containers:
      - name: nfs-server
        image: k8s.gcr.io/volume-nfs:0.8
        ports:
        - name: nfs
          containerPort: 2049
        - name: mountd
          containerPort: 20048
        - name: rpcbind
          containerPort: 111
        securityContext:
          privileged: true
        volumeMounts:
          - name: storage
            mountPath: /exports
      volumes:
        - name: storage
          hostPath:
            path: /data/nfs # store all data in "/data/nfs" directory of the node where it is running
            type: DirectoryOrCreate # if the directory does not exist then create it

---
apiVersion: v1
kind: Service
metadata:
  name: nfs-service
  namespace: workspace
spec:
  ports:
  - name: nfs
    port: 2049
  - name: mountd
    port: 20048
  - name: rpcbind
    port: 111
  selector:
    app: nfs-server # must match with the label of NFS pod

--- 
# nfs persistent volume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs-pv
  namespace: workspace
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteMany
  nfs:
    #server: nfs-service
    server: "10.245.18.37"
    path: "/nfs-direct" # "nfs-direct" folder must exist inside "/exports" directory of NFS server
  mountOptions:
    #- noac
    #- actimeo=0
  persistentVolumeReclaimPolicy: Retain

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nfs-pvc
  namespace: workspace
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: ""
  volumeName: nfs-pv



---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: editor
spec:
  replicas: 1
  # select node by label
  selector:
    matchLabels:
      app: editor
  template:
    metadata:
      labels:
        app: editor
    spec:
      nodeSelector:
        mylabel: ext
      containers:
      - name: editor-container
        image: dadiorchen/editor:1.0
        resources:
          requests:
            memory: "5000Mi"
          limits:
            memory: "8000Mi"
        command: 
          - /bin/bash
          - -c
          - -l
          - |
            apt install -y tmux unzip sudo
            sh -c 'curl -fLo "${XDG_DATA_HOME:-$HOME/.local/share}"/nvim/site/autoload/plug.vim --create-dirs \
              https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim'
            mkdir -p /root/.config
            ln -s /mnt/data/config-nvim /root/.config/nvim
            ln -s /mnt/data/gh /root/.config/gh
            ln -s /mnt/data/github-copilot /root/.config/github-copilot
            ln -s /mnt/data/.gitconfig /root/.gitconfig
            nvim +PlugInstall +qall
            curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash && \
            source /root/.nvm/nvm.sh && \
            npm install -g typescript-language-server
            # install aws cli
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip" && \
            unzip awscliv2.zip && \
            sudo ./aws/install

            cat <<EOF >> /root/.bashrc
            alias messageMagic='curl -s --form "token=ae2atxr3du9okhqrxk5p7nxgv2rumu" --form "user=uugk4p2q2d9kkoythf4t3dhbqiwofn" --form "message=test ok" --form "sound=magic" https://api.pushover.net/1/messages.json'
            alias messageFail='curl -s --form "token=ae2atxr3du9okhqrxk5p7nxgv2rumu" --form "user=uugk4p2q2d9kkoythf4t3dhbqiwofn" --form "message=test ok" --form "sound=falling" https://api.pushover.net/1/messages.json'
            alias ok='echo ok! && messageMagic || messageFail'
            EOF

            # install kubectl 
            apt-get update && \
            apt-get install -y curl apt-transport-https && \
            curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" && \
            chmod +x ./kubectl && \
            mv ./kubectl /usr/local/bin/kubectl && \

            # shell
            cat <<EOF >> /root/.bashrc
            source '/mnt/data/dadior-shell-config/aliases.sh'
            EOF

            # docker
            # Add Docker's official GPG key:
            apt-get update
            apt-get -y install ca-certificates curl
            install -m 0755 -d /etc/apt/keyrings
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
            chmod a+r /etc/apt/keyrings/docker.asc

            # Add the repository to Apt sources:
            echo \
              "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
              $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
              sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt-get update

            apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin


            tail -f /dev/null
        env:
        - name: NODE_OPTIONS
          value: "--max-old-space-size=4096"
        volumeMounts:
        - mountPath: "/mnt/data"
          name: workspace-volume
        - name: docker-socket
          mountPath: /var/run/docker.sock
      volumes:
        - name: workspace-volume
          persistentVolumeClaim:
            claimName: nfs-pvc
        - name: docker-socket
          hostPath:
            path: /var/run/docker.sock
      priorityClassName: high-priority

---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: desktop
spec:
  replicas: 1
  selector:
    matchLabels:
      app: desktop
  template:
    metadata:
      labels:
        app: desktop
    spec:
      nodeSelector:
        mylabel: ext
      containers:
      - name: desktop-container
        image: dadiorchen/desktop:1.0
        resources:
          requests:
            memory: "2000Mi"
          limits:
            memory: "10000Mi"
        command: 
          - /bin/bash
          - --login
          - -c
          - |
            # run the startup script in the background
            export STARTUPDIR=/dockerstartup
            source /etc/profile
            source /root/.bashrc
            source /home/kasm-user/.bashrc
            curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash && \
            source /root/.nvm/nvm.sh && \
            nvm install 18 && \
            nvm use 18 && \
            cd /mnt/data/bluebot-saas-client/ && \
            npx cypress install && \
            cd /mnt/data/a-thing/mono/apps/web/ && \
            npx cypress install && \
            /dockerstartup/kasm_default_profile.sh && \
            /dockerstartup/vnc_startup.sh && \
            /dockerstartup/kasm_startup.sh
        securityContext:
          runAsUser: 0
          runAsGroup: 0
        # env VNC_PW=123456
        env:
        - name: VNC_PW
          value: "Cy;{C52<48aM"
        - name: NODE_OPTIONS
          value: "--max-old-space-size=1024"
        volumeMounts:
        - mountPath: "/mnt/data"
          name: workspace-volume
      volumes:
        - name: workspace-volume
          persistentVolumeClaim:
            claimName: nfs-pvc

---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: server
  template:
    metadata:
      labels:
        app: server
    spec:
      nodeSelector:
        mylabel: ext
      containers:
      - name: desktop-container
        image: dadiorchen/editor:1.0
        resources:
          requests:
            memory: "500Mi"
          limits:
            memory: "2000Mi"
        #command to run npm start
        command: 
          - /bin/bash
          - -c
          - |
            source /root/.nvm/nvm.sh
            cd /mnt/data/bluebot-saas-client/
            IS_CYPRESS_TEST=true IS_CYPRESS_INT_TEST=true npm run dev -- --experimental-https
            npm run dev -- --experimental-https
        env:
        - name: NODE_OPTIONS
          value: "--max-old-space-size=2048"
        volumeMounts:
        - mountPath: "/mnt/data"
          name: workspace-volume
      volumes:
        - name: workspace-volume
          persistentVolumeClaim:
            claimName: nfs-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: server-service
  namespace: workspace
spec:
  ports:
    - port: 3001
      targetPort: 3001
  selector:
    app: server

---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: server-a-thing
spec:
  replicas: 0
  selector:
    matchLabels:
      app: server-a-thing
  template:
    metadata:
      labels:
        app: server-a-thing
    spec:
      nodeSelector:
        mylabel: ext
      containers:
      - name: desktop-container
        image: dadiorchen/editor:1.0
        #command to run npm start
        command: 
          - /bin/bash
          - -c
          - |
            source /root/.nvm/nvm.sh
            cd /mnt/data/a-thing/mono/apps/web
            #IS_CYPRESS_TEST=true IS_CYPRESS_INT_TEST=true npm run dev -- --experimental-https
            #npm run dev -- --experimental-https
            npm run dev 
        env:
        volumeMounts:
        - mountPath: "/mnt/data"
          name: workspace-volume
      volumes:
      - name: workspace-volume
        nfs:
          #server: "nfs-service.workspace.svc.cluster.local"
          server: "10.245.18.37"
          path: "/nfs-direct" # "nfs-direct" folder must exist inside "/exports" directory of NFS server

---
apiVersion: v1
kind: Service
metadata:
  name: server-a-thing-service
  namespace: workspace
spec:
  ports:
    - port: 3000
      targetPort: 3000
  selector:
    app: server-a-thing

---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: server-a-thing-api
spec:
  replicas: 0
  selector:
    matchLabels:
      app: server-a-thing-api
  template:
    metadata:
      labels:
        app: server-a-thing-api
    spec:
      nodeSelector:
        mylabel: ext
      containers:
      - name: desktop-container
        image: dadiorchen/editor:1.0
        #command to run npm start
        command: 
          - /bin/bash
          - -c
          - |
            source /root/.nvm/nvm.sh
            cd /mnt/data/a-thing/mono/apps/server
            #IS_CYPRESS_TEST=true IS_CYPRESS_INT_TEST=true npm run dev -- --experimental-https
            #npm run dev -- --experimental-https
            npx --yes ts-node index.ts
        env:
        volumeMounts:
        - mountPath: "/mnt/data"
          name: workspace-volume
      volumes:
      - name: workspace-volume
        nfs:
          #server: "nfs-service.workspace.svc.cluster.local"
          server: "10.245.18.37"
          path: "/nfs-direct" # "nfs-direct" folder must exist inside "/exports" directory of NFS server

---
apiVersion: v1
kind: Service
metadata:
  name: server-a-thing-api-service
  namespace: workspace
spec:
  ports:
    - port: 3000
      targetPort: 3000
  selector:
    app: server-a-thing-api



---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: editor-aws
spec:
  replicas: 0
  # select node by label
  selector:
    matchLabels:
      app: editor-aws
  template:
    metadata:
      labels:
        app: editor-aws
    spec:
      nodeSelector:
        mylabel: core
      containers:
      - name: editor-container
        image: dadiorchen/editor:1.0
        command: 
          - /bin/bash
          - -c
          - -l
          - |
            apt install -y tmux sudo unzip
            sh -c 'curl -fLo "${XDG_DATA_HOME:-$HOME/.local/share}"/nvim/site/autoload/plug.vim --create-dirs \
              https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim'
            mkdir -p /root/.config
            ln -s /mnt/data/config-nvim /root/.config/nvim
            nvim +PlugInstall +qall
            curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.1/install.sh | bash && \
            source /root/.nvm/nvm.sh && \
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip" && \
            unzip awscliv2.zip && \
            sudo ./aws/install
            tail -f /dev/null
        env:
        volumeMounts:
        - mountPath: "/mnt/data"
          name: workspace-volume
      volumes:
      - name: workspace-volume
        nfs:
          #server: "nfs-service.workspace.svc.cluster.local"
          server: "10.244.28.157"
          path: "/nfs-direct" # "nfs-direct" folder must exist inside "/exports" directory of NFS server
      priorityClassName: high-priority


# postgres
---
# postgres deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: postgres
spec:
  replicas: 0
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      nodeSelector:
        mylabel: core
      containers:
        - name: postgres
          image: postgres:13
          env:
          - name: POSTGRES_USER
            value: "postgres"
          - name: POSTGRES_PASSWORD
            value: "postgres"
          - name: POSTGRES_DB
            value: "postgres"
          - name: POSTGRES_HOST_AUTH_METHOD
            value: "trust"

---
# postgres service
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: workspace
spec:
  ports:
    - port: 5432
  selector:
    app: postgres

---
# postgREST Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workspace
  name: postgrest
spec:
  replicas: 0
  selector:
    matchLabels:
      app: postgrest
  template:
    metadata:
      labels:
        app: postgrest
    spec:
      nodeSelector:
        mylabel: core
      containers:
        - name: postgrest
          image: postgrest/postgrest:latest
          env:
          - name: PGRST_DB_URI
            value: "postgresql://postgres:postgres@postgres.workspace.svc.cluster.local:5432/thing"
          - name: PGRST_DB_ANON_ROLE
            value: "web_anon"

---
# postgREST service
apiVersion: v1
kind: Service
metadata:
  name: postgrest
  namespace: workspace
spec:
  ports:
    - port: 3000
  selector:
    app: postgrest


---
# DaemonSet to set up swap
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: swap-daemonset
spec:
  selector:
    matchLabels:
      app: swap
  template:
    metadata:
      labels:
        app: swap
    spec:
      containers:
      - name: swap-container
        image: ubuntu
        command: ["/bin/sh", "-c"]
        args: 
          - |
            echo 'set up swap'
            swapoff /root/swapfile
            rm /root/swapfile
            #truncate -s 0 /swapfile
            #chattr +C /swapfile
            fallocate -l 16G /root/swapfile
            #dd if=/dev/zero of=/swapfile bs=1M count=4096
            echo $?
            ls -l /root
            sleep 10
            chmod 600 /root/swapfile
            mkswap /root/swapfile
            echo $?
            sleep 10
            swapon /root/swapfile
            swapon --show
            sysctl vm.swappiness=100
            cat /proc/sys/vm/swappiness
            tail -f /dev/null
        securityContext:
          privileged: true  # Run in privileged mode
        volumeMounts:
        - mountPath: /root
          name: my-host-path
      volumes:
      - name: my-host-path
        hostPath:
          path: /root
      hostPID: true  # Use the host's PID namespace

---
# permission
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: workspace
  name: exec-role
rules:
- apiGroups: ["", "apps"]
  resources: ["pods", "deployments"]
  verbs: ["get", "list", "exec"]
- apiGroups: ["", "apps"]
  resources: ["pods/exec", "deployments/exec"]
  verbs: ["create"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: exec-role-binding
  namespace: workspace
subjects:
- kind: ServiceAccount
  name: default  # Use the default service account or create a new one
  namespace: workspace
roleRef:
  kind: Role
  name: exec-role
  apiGroup: rbac.authorization.k8s.io


